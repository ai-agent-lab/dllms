<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="A comprehensive survey of diffusion-based large language models, exploring their evolution, applications, and future directions.">
  <meta property="og:title" content="Diffusion-based Large Language Models Survey"/>
  <meta property="og:description" content="Comprehensive survey covering DLLMs from foundational concepts to cutting-edge applications"/>
  <meta property="og:url" content="https://www.techrxiv.org/users/952417/articles/1321784-diffusion-based-large-language-models-survey"/>
  <meta property="og:image" content="static/images/banner.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="Diffusion-based Large Language Models Survey">
  <meta name="twitter:description" content="Comprehensive survey of DLLMs: evolution, applications, and future directions">
  <meta name="twitter:image" content="static/images/banner.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Diffusion Models, Large Language Models, DLLMs, Text Generation, Survey, Machine Learning, NLP">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Diffusion-based Large Language Models Survey</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Diffusion-based Large Language Models Survey</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="mailto:ctseng@luxmuse.ai" target="_blank">Chiung-Yi Tseng</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="mailto:danyang@vokram.com" target="_blank">Danyang Zhang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="mailto:bi32@purdue.edu" target="_blank">Ziqian Bi</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="mailto:junhao.song23@imperial.ac.uk" target="_blank">Junhao Song</a><sup>3,†</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>AI Agent Lab, Vokram Group, London, UK</span><br>
              <span class="author-block"><sup>2</sup>Purdue University, USA</span><br>
              <span class="author-block"><sup>3</sup>Imperial College London, UK</span><br>
              <span class="eql-cntrb"><small><br><sup>†</sup>Corresponding Author</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- TechRxiv link -->
                <span class="link-block">
                  <a href="https://www.techrxiv.org/users/952417/articles/1321784-diffusion-based-large-language-models-survey" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/ai-agent-lab/Diffusion-based-Large-Language-Models-Survey" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
                </span>

                <!-- Dataset Link -->
                <span class="link-block">
                  <a href="#bibliography" 
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-book"></i>
                  </span>
                  <span>Bibliography</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Diffusion-based large language models (DLLMs) have emerged as a promising alternative to traditional autoregressive architectures, 
              notably enhancing parallel generation, controllability, and robustness across multiple modalities. Originally developed from 
              continuous diffusion methods in computer vision, recent adaptations of DLLMs have tailored discrete diffusion processes through 
              absorbing-state kernels, latent projections, and hybrid architectures.
            </p>
            <p>
              This survey reviews recent developments in DLLMs, beginning with their foundational concepts, including DDPM, DDIM, and their 
              early discrete adaptations, such as mask-based, continuous-embedding, and hybrid models. We organize current methods by sampling 
              strategy, guidance type, noise schedule, and temporal conditioning, and analyzes their efficiency, output quality, and fine-tuning.
            </p>
            <p>
              The paper also highlights key advancements: autoregressive-diffusion unification through hyperschedules, adaptive correction 
              sampling, and efficient caching mechanisms to enhance computational performance. Besides, it explores emerging applications, 
              such as natural language tasks, multimodal generation, and reasoning-intensive domains. These demonstrate the versatility of DLLMs.
            </p>
            <p>
              Furthermore, the paper identifies critical challenges, including adaptive sampling, scalable alignment strategies, deeper 
              integration with pretrained language models, graph-based diffusion frameworks, and robust evaluation protocols. Finally, 
              the paper proposes directions that could define future research in diffusion-based sequence generation.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Key Contributions -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full">
          <h2 class="title is-3">Key Contributions</h2>
          <div class="content">
            <ul>
              <li><strong>Comprehensive Taxonomy:</strong> We provide a systematic categorization of diffusion language models based on their architectural choices, training objectives, and sampling strategies.</li>
              <li><strong>Evolution Analysis:</strong> We trace the development from continuous diffusion models to discrete variants specifically designed for text generation.</li>
              <li><strong>Performance Evaluation:</strong> We analyze the trade-offs between different approaches in terms of generation quality, computational efficiency, and controllability.</li>
              <li><strong>Future Directions:</strong> We identify promising research directions including adaptive sampling, scalable alignment, and integration with existing LLMs.</li>
              <li><strong>Extensive Bibliography:</strong> We compile 87 key papers with verified links to help researchers navigate this rapidly evolving field.</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper Sections Overview -->
  <section class="section hero is-small is-light">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Survey Structure</h2>
      <div class="columns is-multiline">
        <div class="column is-one-third">
          <div class="box">
            <h3 class="title is-5">Evolution & Foundations</h3>
            <ul>
              <li>Historical Development</li>
              <li>Core Challenges</li>
              <li>Categorization Methods</li>
            </ul>
          </div>
        </div>
        <div class="column is-one-third">
          <div class="box">
            <h3 class="title is-5">Technical Advances</h3>
            <ul>
              <li>Interoperability with AR Models</li>
              <li>Knowledge Transfer</li>
              <li>Inference Speed Optimization</li>
            </ul>
          </div>
        </div>
        <div class="column is-one-third">
          <div class="box">
            <h3 class="title is-5">Applications & Future</h3>
            <ul>
              <li>Multimodality & Reasoning</li>
              <li>Evaluation Metrics</li>
              <li>Future Research Directions</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Key Figures -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Key Figures</h2>
      <div class="columns is-centered">
        <div class="column is-full">
          <div class="columns is-multiline">
            <div class="column is-half">
              <figure class="image">
                <img src="Overleaf/figs/diffusion.pdf" alt="Diffusion Process">
                <p class="has-text-centered"><strong>Figure 1:</strong> The Diffusion Process in Language Models</p>
              </figure>
            </div>
            <div class="column is-half">
              <figure class="image">
                <img src="Overleaf/figs/DLLMs_timeline.pdf" alt="Timeline">
                <p class="has-text-centered"><strong>Figure 2:</strong> Evolution Timeline of DLLMs</p>
              </figure>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Bibliography Section -->
  <section class="section hero is-light" id="bibliography">
    <div class="container is-max-desktop content">
      <h2 class="title">Bibliography</h2>
      <p>This survey covers 87 key papers in the field of diffusion-based language models. Click on any paper title to access it directly.</p>
      
      <h3>Evolution of Diffusion Language Models</h3>
      <div class="publication-list">
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/1503.03585" target="_blank"><em>Deep Unsupervised Learning using Nonequilibrium Thermodynamics</em></a>, Sohl-Dickstein et al. 
            <a href="https://arxiv.org/abs/1503.03585" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2015-red" alt="arXiv 2015">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2006.11239" target="_blank"><em>Denoising Diffusion Probabilistic Models</em></a>, Ho et al. 
            <a href="https://arxiv.org/abs/2006.11239" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2020-red" alt="arXiv 2020">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2010.02502" target="_blank"><em>Denoising Diffusion Implicit Models</em></a>, Song et al. 
            <a href="https://arxiv.org/abs/2010.02502" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2021-red" alt="arXiv 2021">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2205.14217" target="_blank"><em>Diffusion-LM Improves Controllable Text Generation</em></a>, Li et al. 
            <a href="https://arxiv.org/abs/2205.14217" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2022-red" alt="arXiv 2022">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2210.08933" target="_blank"><em>DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models</em></a>, Gong et al. 
            <a href="https://arxiv.org/abs/2210.08933" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2112.07804" target="_blank"><em>SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers</em></a>, Yuan et al. 
            <a href="https://arxiv.org/abs/2112.07804" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2022-red" alt="arXiv 2022">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2206.09010" target="_blank"><em>Composable Text Controls in Latent Space with ODEs</em></a>, Liu et al. 
            <a href="https://arxiv.org/abs/2206.09010" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2022-red" alt="arXiv 2022">
            </a>
          </span>
        </div>
      </div>

      <h3>Categorization and Methods</h3>
      <div class="publication-list">
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10909201/" target="_blank"><em>Diffusion models in text generation: a survey</em></a>, Yi et al. 
            <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10909201/" target="_blank">
              <img src="https://img.shields.io/badge/NCBI-2024-blue" alt="NCBI 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2305.14671" target="_blank"><em>A Survey of Diffusion Models in Natural Language Processing</em></a>, Zou et al. 
            <a href="https://arxiv.org/abs/2305.14671" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2303.07576" target="_blank"><em>Diffusion Models in NLP: A Survey</em></a>, Zhu & Zhao 
            <a href="https://arxiv.org/abs/2303.07576" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2209.00796" target="_blank"><em>Diffusion Models: A Comprehensive Survey of Methods and Applications</em></a>, Yang et al. 
            <a href="https://arxiv.org/abs/2209.00796" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2406.07524" target="_blank"><em>Simple and Effective Masked Diffusion Language Models</em></a>, Sahoo et al. 
            <a href="https://arxiv.org/abs/2406.07524" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2503.04482" target="_blank"><em>Generalized Interpolating Discrete Diffusion</em></a>, Rütte et al. 
            <a href="http://arxiv.org/abs/2503.04482" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2310.05793" target="_blank"><em>Text Diffusion with Reinforcement Learning</em></a>, Wang et al. 
            <a href="https://arxiv.org/abs/2310.05793" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2304.05729" target="_blank"><em>Cheaper Diffusion</em></a>, Chen et al. 
            <a href="https://arxiv.org/abs/2304.05729" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2310.16834" target="_blank"><em>Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution</em></a>, Lou et al. 
            <a href="https://arxiv.org/abs/2310.16834" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
      </div>

      <h3>Interoperability and Knowledge Transfer</h3>
      <div class="publication-list">
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2410.17891" target="_blank"><em>Scaling Diffusion Language Models via Adaptation from Autoregressive Models</em></a>, Gong et al. 
            <a href="https://arxiv.org/abs/2410.17891" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2504.06416" target="_blank"><em>Unifying Autoregressive and Diffusion-Based Sequence Generation</em></a>, Fathi et al. 
            <a href="https://arxiv.org/abs/2504.06416" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2503.09573" target="_blank"><em>Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models</em></a>, Arriola et al. 
            <a href="https://arxiv.org/abs/2503.09573" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2305.09515" target="_blank"><em>AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation</em></a>, Wu et al. 
            <a href="http://arxiv.org/abs/2305.09515" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2402.19097" target="_blank"><em>TEncDM: Understanding the Properties of the Diffusion Model in the Space of Language Model Encodings</em></a>, Shabalin et al. 
            <a href="http://arxiv.org/abs/2402.19097" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2301.10677" target="_blank"><em>Latent Diffusion for Language Generation</em></a>, Lovelace et al. 
            <a href="https://arxiv.org/abs/2301.10677" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2305.13269" target="_blank"><em>Continuous diffusion for mixed-type tabular data</em></a>, Jeon et al. 
            <a href="https://arxiv.org/abs/2305.13269" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
      </div>

      <h3>Collaboration and Inference</h3>
      <div class="publication-list">
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2305.14771" target="_blank"><em>David helps Goliath: Inference-Time Collaboration Between Small Specialized and Large General Diffusion LMs</em></a>, Han et al. 
            <a href="http://arxiv.org/abs/2305.14771" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2410.21357" target="_blank"><em>Energy-Based Diffusion Language Models for Text Generation</em></a>, Xu et al. 
            <a href="https://arxiv.org/abs/2410.21357" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2210.17432" target="_blank"><em>SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control</em></a>, Han et al. 
            <a href="http://arxiv.org/abs/2210.17432" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2506.17298" target="_blank"><em>Mercury: Ultra-Fast Language Models Based on Diffusion</em></a>, Khanna et al. 
            <a href="https://arxiv.org/abs/2506.17298" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2503.23077" target="_blank"><em>Efficient Inference for Large Reasoning Models: A Survey</em></a>, Liu et al. 
            <a href="https://arxiv.org/abs/2503.23077" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2310.01201" target="_blank"><em>Speculative Decoding with Big Little Decoder</em></a>, Kim et al. 
            <a href="https://arxiv.org/abs/2310.01201" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2501.11635" target="_blank"><em>Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion</em></a>, Chen et al. 
            <a href="https://arxiv.org/abs/2501.11635" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2402.17177" target="_blank"><em>Accelerated Sampling for Discrete Diffusion Models</em></a>, Bortoli et al. 
            <a href="https://arxiv.org/abs/2402.17177" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
      </div>

      <h3>Fine-Tuning and Optimization</h3>
      <div class="publication-list">
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2311.13231" target="_blank"><em>Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model</em></a>, Yang et al. 
            <a href="http://arxiv.org/abs/2311.13231" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2502.09992" target="_blank"><em>Large Language Diffusion Models</em></a>, Nie et al. 
            <a href="https://arxiv.org/abs/2502.09992" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2502.13917" target="_blank"><em>TESS 2: A Large-Scale Generalist Diffusion Language Model</em></a>, Tae et al. 
            <a href="https://arxiv.org/abs/2502.13917" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2406.11473" target="_blank"><em>Promises, Outlooks and Challenges of Diffusion Language Modeling</em></a>, Deschenaux & Gulcehre 
            <a href="http://arxiv.org/abs/2406.11473" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2310.09720" target="_blank"><em>Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions</em></a>, Ma et al. 
            <a href="https://arxiv.org/abs/2310.09720" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2402.01802" target="_blank"><em>DiffuTE: Diffusion-based Text Editing with Large Language Models</em></a>, Chen et al. 
            <a href="https://arxiv.org/abs/2402.01802" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2310.11685" target="_blank"><em>Text Diffusion with Encoder-Decoder Transformers</em></a>, Lin et al. 
            <a href="https://arxiv.org/abs/2310.11685" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
      </div>

      <h3>Multimodality and Reasoning</h3>
      <div class="publication-list">
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2402.07754" target="_blank"><em>Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models</em></a>, Ye et al. 
            <a href="https://arxiv.org/abs/2402.07754" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2504.12216" target="_blank"><em>d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning</em></a>, Zhao et al. 
            <a href="https://arxiv.org/abs/2504.12216" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2503.04606" target="_blank"><em>The Best of Both Worlds: Integrating Language Models and Diffusion Models for Video Generation</em></a>, Yin et al. 
            <a href="https://arxiv.org/abs/2503.04606" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2404.07499" target="_blank"><em>Diff-ZSvQA: Zero-Shot Video Question Answering via Diffusion Models</em></a>, Xu et al. 
            <a href="https://arxiv.org/abs/2404.07499" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2402.13916" target="_blank"><em>HybridVLA: Vision-Language Action Model for Robotics</em></a>, Liu et al. 
            <a href="https://arxiv.org/abs/2402.13916" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2405.11365" target="_blank"><em>Are Diffusion Models Really Inferior to Autoregressive Counterparts for Text Generation?</em></a>, Krojer et al. 
            <a href="https://arxiv.org/abs/2405.11365" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
      </div>

      <h3>Applications</h3>
      <div class="publication-list">
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2406.12044" target="_blank"><em>ARTIST: Improving the Generation of Text-rich Images with Disentangled Diffusion Models and Large Language Models</em></a>, Zhang et al. 
            <a href="http://arxiv.org/abs/2406.12044" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2305.10855" target="_blank"><em>TextDiffuser: Diffusion Models as Text Painters</em></a>, Chen et al. 
            <a href="http://arxiv.org/abs/2305.10855" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://deepmind.google/models/gemini-diffusion/" target="_blank"><em>Gemini Diffusion</em></a>, Google DeepMind 
            <a href="https://deepmind.google/models/gemini-diffusion/" target="_blank">
              <img src="https://img.shields.io/badge/DeepMind-2025-blue" alt="DeepMind 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2306.02531" target="_blank"><em>PLANNER: Generating Diversified Paragraph via Latent Language Diffusion Model</em></a>, Zhang et al. 
            <a href="http://arxiv.org/abs/2306.02531" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2410.13782" target="_blank"><em>DPLM-2: A Multimodal Diffusion Protein Language Model</em></a>, Wang et al. 
            <a href="http://arxiv.org/abs/2410.13782" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2407.18279" target="_blank"><em>P3Sum: Summarization with Privacy-Preserving and Personalized Prompts</em></a>, Liu et al. 
            <a href="https://arxiv.org/abs/2407.18279" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2311.04726" target="_blank"><em>Constrained Discrete Diffusion Generation via Mixed-Integer Programming</em></a>, Cardei et al. 
            <a href="https://arxiv.org/abs/2311.04726" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2501.08503" target="_blank"><em>DDPT: Diffusion-based Dual-space Pre-trained Transformers for Image-text Matching</em></a>, Li et al. 
            <a href="https://arxiv.org/abs/2501.08503" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2310.04541" target="_blank"><em>Survey of Hallucination in Natural Language Generation</em></a>, Cao et al. 
            <a href="https://arxiv.org/abs/2310.04541" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2306.08257" target="_blank"><em>Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning</em></a>, Meshchaninov et al. 
            <a href="https://arxiv.org/abs/2306.08257" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
      </div>

      <h3>Foundational Models and Theory</h3>
      <div class="publication-list">
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2305.18619" target="_blank"><em>Likelihood-Based Diffusion Language Models</em></a>, Gulrajani & Hashimoto 
            <a href="https://arxiv.org/abs/2305.18619" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2209.00796" target="_blank"><em>Diffusion Models: A Comprehensive Survey of Methods and Applications</em></a>, Yang et al. 
            <a href="https://arxiv.org/abs/2209.00796" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2022-red" alt="arXiv 2022">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2111.14822" target="_blank"><em>Structured Denoising Diffusion Models in Discrete State-Spaces</em></a>, Austin et al. 
            <a href="https://arxiv.org/abs/2111.14822" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2021-red" alt="arXiv 2021">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2411.06438" target="_blank"><em>Conditional [MASK] Discrete Diffusion Language Model</em></a>, Koh et al. 
            <a href="http://arxiv.org/abs/2411.06438" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2302.13971" target="_blank"><em>DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models</em></a>, He et al. 
            <a href="https://arxiv.org/abs/2302.13971" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2209.06183" target="_blank"><em>A Continuous Time Framework for Discrete Denoising Models</em></a>, Campbell et al. 
            <a href="https://arxiv.org/abs/2209.06183" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2022-red" alt="arXiv 2022">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2404.07499" target="_blank"><em>DEEM: Diffusion Models Serve as the Eyes of Large Language Models for Image Perception</em></a>, Luo et al. 
            <a href="https://arxiv.org/abs/2404.07499" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2402.14184" target="_blank"><em>DiffPO: Diffusion Model Policy Optimization</em></a>, Chen et al. 
            <a href="https://arxiv.org/abs/2402.14184" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2501.09236" target="_blank"><em>Amortizing Intractable Inference in Diffusion Models for Vision, Language, and Control</em></a>, Venkatraman et al. 
            <a href="https://arxiv.org/abs/2501.09236" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2410.08707" target="_blank"><em>Large Concept Models for Structured Prediction</em></a>, Cetin et al. 
            <a href="https://arxiv.org/abs/2410.08707" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2501.03482" target="_blank"><em>Text-Driven Video Generation with Natural Language Processing</em></a>, He et al. 
            <a href="https://arxiv.org/abs/2501.03482" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
      </div>

      <h3>Additional Diffusion Language Models</h3>
      <div class="publication-list">
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2304.04746" target="_blank"><em>A Cheaper and Better Diffusion Language Model with Soft-Masked Noise</em></a>, Chen et al. 
            <a href="http://arxiv.org/abs/2304.04746" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2102.09672" target="_blank"><em>Improved Denoising Diffusion Probabilistic Models</em></a>, Nichol & Dhariwal 
            <a href="https://arxiv.org/abs/2102.09672" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2021-red" alt="arXiv 2021">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="https://arxiv.org/abs/2207.12598" target="_blank"><em>Classifier-Free Diffusion Guidance</em></a>, Ho & Salimans 
            <a href="https://arxiv.org/abs/2207.12598" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2022-red" alt="arXiv 2022">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2502.11564" target="_blank"><em>Continuous Diffusion Model for Language Modeling</em></a>, Jo & Hwang 
            <a href="http://arxiv.org/abs/2502.11564" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2406.04329" target="_blank"><em>Simplified and Generalized Masked Diffusion for Discrete Data</em></a>, Shi et al. 
            <a href="http://arxiv.org/abs/2406.04329" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2302.05737" target="_blank"><em>A Reparameterized Discrete Diffusion Model for Text Generation</em></a>, Zheng et al. 
            <a href="http://arxiv.org/abs/2302.05737" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2406.03736" target="_blank"><em>Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data</em></a>, Ou et al. 
            <a href="http://arxiv.org/abs/2406.03736" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2311.12908" target="_blank"><em>Diffusion Model Alignment Using Direct Preference Optimization</em></a>, Wallace et al. 
            <a href="http://arxiv.org/abs/2311.12908" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2408.05636" target="_blank"><em>Speculative Diffusion Decoding: Accelerating Language Generation through Diffusion</em></a>, Christopher et al. 
            <a href="http://arxiv.org/abs/2408.05636" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2501.05370" target="_blank"><em>Accelerated Diffusion Models via Speculative Sampling</em></a>, De Bortoli et al. 
            <a href="http://arxiv.org/abs/2501.05370" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2212.11685" target="_blank"><em>Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise</em></a>, Lin et al. 
            <a href="http://arxiv.org/abs/2212.11685" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2022-red" alt="arXiv 2022">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2406.11831" target="_blank"><em>Exploring the Role of Large Language Models in Prompt Encoding for Diffusion Models</em></a>, Ma et al. 
            <a href="http://arxiv.org/abs/2406.11831" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2503.09790" target="_blank"><em>Constrained Language Generation with Discrete Diffusion Models</em></a>, Cardei et al. 
            <a href="http://arxiv.org/abs/2503.09790" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2407.10998" target="_blank"><em>Discrete Diffusion Language Model for Efficient Text Summarization</em></a>, Dat et al. 
            <a href="http://arxiv.org/abs/2407.10998" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2403.03726" target="_blank"><em>Diffusion on Language Model Encodings for Protein Sequence Generation</em></a>, Meshchaninov et al. 
            <a href="http://arxiv.org/abs/2403.03726" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2024-red" alt="arXiv 2024">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2503.15914" target="_blank"><em>Text-Driven Diffusion Model for Sign Language Production</em></a>, He et al. 
            <a href="http://arxiv.org/abs/2503.15914" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2501.15781" target="_blank"><em>Large Language Models to Diffusion Finetuning</em></a>, Cetin et al. 
            <a href="http://arxiv.org/abs/2501.15781" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2311.09741" target="_blank"><em>P3SUM: Preserving Author's Perspective in News Summarization with Diffusion Language Models</em></a>, Liu et al. 
            <a href="http://arxiv.org/abs/2311.09741" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2305.16397" target="_blank"><em>Are Diffusion Models Vision-And-Language Reasoners?</em></a>, Krojer et al. 
            <a href="http://arxiv.org/abs/2305.16397" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2501.19040" target="_blank"><em>Towards the Worst-case Robustness of Large Language Models</em></a>, Chen et al. 
            <a href="http://arxiv.org/abs/2501.19040" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2025-red" alt="arXiv 2025">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2301.09642" target="_blank"><em>DiffSDS: A Language Diffusion Model for Protein Backbone Inpainting under Geometric Conditions and Constraints</em></a>, Gao et al. 
            <a href="http://arxiv.org/abs/2301.09642" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2023-red" alt="arXiv 2023">
            </a>
          </span>
        </div>
        <div class="publication-item">
          <span class="publication-title">
            <a href="http://arxiv.org/abs/2209.02646" target="_blank"><em>A Survey on Generative Diffusion Model</em></a>, Cao et al. 
            <a href="http://arxiv.org/abs/2209.02646" target="_blank">
              <img src="https://img.shields.io/badge/arXiv-2022-red" alt="arXiv 2022">
            </a>
          </span>
        </div>
      </div>

    </div>
  </section>

  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{tseng2025diffusion,
  title={Diffusion-based Large Language Models Survey},
  author={Tseng, Chiung-Yi and Zhang, Danyang and Bi, Ziqian and Song, Junhao},
  journal={TechRxiv},
  year={2025},
  url={https://www.techrxiv.org/users/952417/articles/1321784-diffusion-based-large-language-models-survey}
}</code></pre>
    </div>
  </section>

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
              This webpage template was borrowed from <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>